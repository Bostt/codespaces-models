{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with GitHub Models - OpenAI SDK\n",
    "\n",
    "## 1. Personal access token\n",
    "\n",
    "A personal access token is made available in the Codespaces environment in the `GITHUB_TOKEN` environment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --quiet\n",
    "%pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3. Set environment variables and create the client\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if not os.getenv(\"GITHUB_TOKEN\"):\n",
    "    raise ValueError(\"GITHUB_TOKEN is not set\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"GITHUB_TOKEN\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://models.inference.ai.azure.com/\"\n",
    "\n",
    "\n",
    "model_name = \"gpt-4o-mini\" # or \"gpt-4o\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run a basic code sample\n",
    "\n",
    "This is just calling the `chat.completions` endpoint with a simple prompt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the capital of France?\",\n",
    "        }\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Turn Conversation\n",
    "\n",
    "This sample demonstrates a multi-turn conversation with the chat completion API.\n",
    "When using the model for a chat application, you'll need to manage the history of that\n",
    "conversation and send the latest messages to the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Spain is Madrid.\n"
     ]
    }
   ],
   "source": [
    "# Call the chat completion API\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the capital of France?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"The capital of France is Paris.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What about Spain?\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using images as inputs\n",
    "\n",
    "The `gpt-4o-mini` model supports using images as inputs. To run a chat completion using\n",
    "a local image file, use the following sample. To send it to the service, you'll need to encode the image as **data URI**, which is a string that starts with `data:image/png;base64,` followed by the base64-encoded image.\n",
    "We are using this small image as an example: \n",
    "\n",
    "![image](./sample.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image features a cute, fluffy puppy with a golden coat seated on a textured mat. In front of the puppy is a black and gray food bowl, which reflects the surroundings. The floor appears to be wooden, and there are elements of a cozy environment visible in the background, including a brick wall and wooden furniture. The overall atmosphere of the image is warm and inviting.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "def get_image_data_url(image_file: str, image_format: str) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to converts an image file to a data URL string.\n",
    "\n",
    "    Args:\n",
    "        image_file (str): The path to the image file.\n",
    "        image_format (str): The format of the image file.\n",
    "\n",
    "    Returns:\n",
    "        str: The data URL of the image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(image_file, \"rb\") as f:\n",
    "            image_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Could not read '{image_file}'.\")\n",
    "        exit()\n",
    "    return f\"data:image/{image_format};base64,{image_data}\"\n",
    "\n",
    "\n",
    "# Call the chat completion API\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that describes images in detail.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What's in this image?\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        # using a file located in this directory\n",
    "                        \"url\": get_image_data_url(\"./sample.png\", \"png\")\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming the response\n",
    "\n",
    "For a better user experience, you will want to stream the response of the model\n",
    "so that the first token shows up early and you avoid waiting for long responses.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercising every day offers numerous benefits for both your physical and mental well-being. Here are five compelling reasons to make daily exercise a part of your routine:\n",
      "\n",
      "1. **Improved Physical Health**: Regular exercise strengthens your heart, improves circulation, boosts your immune system, and helps maintain a healthy weight. It can lower the risk of chronic diseases such as heart disease, type 2 diabetes, and certain cancers.\n",
      "\n",
      "2. **Enhanced Mental Well-being**: Physical activity releases endorphins, often referred to as \"feel-good\" hormones. This can reduce feelings of stress, anxiety, and depression while improving your mood and overall emotional health.\n",
      "\n",
      "3. **Increased Energy Levels**: Contrary to what one might expect, regular exercise can lead to increased energy levels. It improves your stamina and reduces fatigue, making daily tasks easier and more enjoyable.\n",
      "\n",
      "4. **Better Sleep Quality**: Engaging in physical activity can help you fall asleep faster and deepen your sleep. Exercise helps regulate your sleep patterns and can alleviate issues like insomnia.\n",
      "\n",
      "5. **Social Connections and Routine**: Exercising daily can provide opportunities for social interaction, whether through group classes, team sports, or simply exercising with friends. Additionally, establishing a regular exercise routine can enhance your sense of discipline and structure in your daily life.\n",
      "\n",
      "Incorporating daily exercise can have a profound impact on multiple dimensions of your health and well-being."
     ]
    }
   ],
   "source": [
    "# Call the chat completion API\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me 5 good reasons why I should exercise every day.\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Print the streamed response\n",
    "for update in response:\n",
    "    if update.choices:\n",
    "        content = update.choices[0].delta.content\n",
    "        if content:\n",
    "            print(content, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tools and Function Calling\n",
    "\n",
    "A language model like `gpt-4o-mini` can be given a set of tools it can ask the calling program to invoke,\n",
    "for running specific actions depending on the context of the conversation.\n",
    "This sample demonstrates how to define a function tool and how to act on a request from the model to invoke it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function `get_flight_info` with arguments {'origin_city': 'Seattle', 'destination_city': 'Miami'}\n",
      "Function returned = {\"airline\": \"Delta\", \"flight_number\": \"DL123\", \"flight_date\": \"May 7th, 2024\", \"flight_time\": \"10:00AM\"}\n",
      "Model response = The next flight from Seattle to Miami is with Delta Airlines. Here are the details:\n",
      "\n",
      "- **Flight Number**: DL123\n",
      "- **Date**: May 7th, 2024\n",
      "- **Time**: 10:00 AM\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a function that returns flight information between two cities (mock implementation)\n",
    "def get_flight_info(origin_city: str, destination_city: str):\n",
    "    if origin_city == \"Seattle\" and destination_city == \"Miami\":\n",
    "        return json.dumps(\n",
    "            {\n",
    "                \"airline\": \"Delta\",\n",
    "                \"flight_number\": \"DL123\",\n",
    "                \"flight_date\": \"May 7th, 2024\",\n",
    "                \"flight_time\": \"10:00AM\",\n",
    "            }\n",
    "        )\n",
    "    return json.dump({\"error\": \"No flights found between the cities\"})\n",
    "\n",
    "\n",
    "# Define a function tool that the model can ask to invoke in order to retrieve flight information\n",
    "tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"\"\"Returns information about the next flight between two cities.\n",
    "            This includes the name of the airline, flight number and the date and time\n",
    "            of the next flight\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"origin_city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the city where the flight originates\",\n",
    "                },\n",
    "                \"destination_city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The flight destination city\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"origin_city\", \"destination_city\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You an assistant that helps users find flight information.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm interested in going to Miami. What is the next flight there from Seattle?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    tools=[tool],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "# We expect the model to ask for a tool call\n",
    "if response.choices[0].finish_reason == \"tool_calls\":\n",
    "\n",
    "    # Append the model response to the chat history\n",
    "    messages.append(response.choices[0].message)\n",
    "\n",
    "    # We expect a single tool call\n",
    "    if (\n",
    "        response.choices[0].message.tool_calls\n",
    "        and len(response.choices[0].message.tool_calls) == 1\n",
    "    ):\n",
    "\n",
    "        tool_call = response.choices[0].message.tool_calls[0]\n",
    "\n",
    "        # We expect the tool to be a function call\n",
    "        if tool_call.type == \"function\":\n",
    "\n",
    "            # Parse the function call arguments and call the function\n",
    "            function_args = json.loads(tool_call.function.arguments.replace(\"'\", '\"'))\n",
    "            print(\n",
    "                f\"Calling function `{tool_call.function.name}` with arguments {function_args}\"\n",
    "            )\n",
    "            callable_func = locals()[tool_call.function.name]\n",
    "            function_return = callable_func(**function_args)\n",
    "            print(f\"Function returned = {function_return}\")\n",
    "\n",
    "            # Append the function call result fo the chat history\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": tool_call.function.name,\n",
    "                    \"content\": function_return,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Get another response from the model\n",
    "            response = client.chat.completions.create(\n",
    "                messages=messages,\n",
    "                tools=[tool],\n",
    "                model=model_name,\n",
    "            )\n",
    "\n",
    "            print(f\"Model response = {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "To learn more about what you can do with the GitHub models using Python, check out the following cookbooks:\n",
    "\n",
    "- [How to process image and video with GPT-4](../../../cookbooks/python/openai/how_to_process_image_and_video_with_gpt4o.ipynb): This notebook shows how to process images and videos with GPT-4.\n",
    "- [How to call functions with chat models](../../../cookbooks/python/openai/How_to_call_functions_with_chat_models.ipynb): This notebook shows how to get GPT-4o to determing which of a set of functions to call to answer a user's question.\n",
    "- [RAG getting started](../../../cookbooks/python/llamaindex/rag_getting_started.ipynb):\n",
    "This Jupyter Notebook demonstrates the use of Retrieval-Augmented Generation (RAG) with LLamaIndex to create a question-answering system that retrieves relevant information from a collection of documents and generates contextually appropriate responses.\n",
    "\n",
    "Or check out [this folder for more cookbooks](../../../cookbooks/python/README.md).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
